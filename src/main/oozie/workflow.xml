<workflow-app name="${jobName}" xmlns="uri:oozie:workflow:0.4">
    <!-- We are looking for a CONTROL.TXT file in their ../raw directory -->
    <parameters>
        <property>
            <name>releaseLabel</name>
        </property>
        <property>
            <name>tableDefFile</name>
        </property>
        <property>
            <name>nameNode</name>
        </property>
        <property>
            <name>jobTracker</name>
        </property>
        <property>
            <name>jobName</name>
        </property>
        <property>
            <name>sourceName</name>
        </property>
        <property>
            <name>toEmailAddress</name>
        </property>
        <property>
            <name>coordTimeInterval</name>
        </property>
        <property>
            <name>tdStageDB</name>
        </property>
        <property>
            <name>tdAuditDB</name>
        </property>
        <property>
            <name>tdServer</name>
        </property>
        <property>
            <name>tdUserID</name>
        </property>
        <property>
            <name>tdUserIDPassword</name>
        </property>
        <property>
            <name>sourceName</name>
        </property>
        <property>
            <name>coordTimeInterval</name>
        </property>
        <property>
            <name>stageOneDataPartition</name>
        </property>
        <property>
            <name>stageOneFinishedDir</name>
        </property>
        <property>
            <name>stageOneExtractedDir</name>
        </property>
        <property>
            <name>stageOneOozieDir</name>
        </property>
        <property>
            <name>stageOneRawDir</name>
        </property>
        <property>
        	<name>stageOnePracticeMappingFile</name>
        </property>
        <property>
                <name>stageOneDivisionMappingFile</name>
        </property>
        <property>
                <name>stageOneEntityMappingFile</name>
        </property>
	<property>
            <name>scriptsDir</name>
        </property>
        <property>
            <name>sqoopConfDir</name>
        </property>
        <property>
            <name>jobFile</name>
        </property>
        <property>
            <name>controlFile</name>
        </property>
        <property>
            <name>workingFile</name>
        </property>
        <property>
            <name>failureFile</name>
        </property>
        <property>
            <name>toEmailAddress</name>
        </property>
        <property>
            <name>sourcePath</name>
        </property>
        <property>
            <name>entity</name>
        </property>
        <property>
            <name>outputPath</name>
        </property>
        <property>
            <name>tdTargetDB</name>
        </property>
    </parameters>

    <start to="check-working-file"/>
    <!-- We are looking for a WORKING.TXT file in their ../raw directory -->
    <!-- If its there then goto END as we must already be working -->
    <!-- If its not being by looking for the CONTROL.TXT file  -->
    <decision name="check-working-file">
        <switch>
            <case to="end">
                ${fs:exists(workingFile)}
            </case>
            <default to="check-control-file"/>
        </switch>
    </decision>
    <!-- We are looking for a CONTROL.TXT file in their ../raw directory -->
    <!-- if we see it we beigin kicking off data ingestion workflows satge-1-->
    <!-- if we DO NOT see it, we look for a _FAILURE file telling us to clean up the dir so they can reattempt in 30 minutes -->
    <decision name="check-control-file">
        <switch>
            <case to="prep-request">
                ${fs:exists(controlFile)}
            </case>
            <default to="check-failure-file"/>
        </switch>
    </decision>
    <!-- We are looking for a _FAILURE  file in their ../raw directory -->
    <!-- if we see it we begin deleting all files in the raw directory stage-1-->
    <!-- if we DO NOT see it, we just end -->
    <decision name="check-failure-file">
        <switch>
            <case to="clean-up-request">
                ${fs:exists(failureFile)}
            </case>
            <default to="end"/>
        </switch>
    </decision>
    <!-- We found a _FAILURE FILE -->
    <!-- We have been requested to clean up all the files in the raw directory stage-1 -->
    <action name="clean-up-request">
        <fs>
            <delete path="${stageOneRawDir}"/>
            <mkdir path='${stageOneRawDir}'/>
            <chmod path='${stageOneRawDir}' permissions='777' dir-files='false'/>
        </fs>
        <!-- We end normally because we succeeded in simply cleaning up -->
        <ok to="end"/>
        <error to="end"/>
    </action>

    <!-- We have been requested to go to work so move the CONTROL.TXT file to WORKING.TXT -->
    <!-- This will ensure if we fire up again while working the second fire-up will       -->
    <!-- simply exit inormally. -->
    <!-- Do any other clean from previous job you need done here NOW -->
    <action name="prep-request">
        <fs>
    <!-- GARY CLEANS FOR TODAYS WORK    ....-->
            <move source="${controlFile}" target="${workingFile}"/>
            <chmod path='${rawDataDir}/*' permissions='777' dir-files='false'/>
        </fs>
        <!-- Even if this step is not needed, and it may not be, move to next step -->
        <ok to="retrieveControlJob"/>
        <error to="retrieveControlJob"/>
    </action>

    <!-- We call controll clean up here in order to clean the working file -->
    <action name="retrieveControlJob">
        <shell xmlns="uri:oozie:shell-action:0.1">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <exec>/usr/bin/python</exec>
            <argument>chsSayControlJob.py</argument>
            <argument>-i</argument>
            <argument>${workingFile}</argument>
            <file>${scriptsDir}/chsSayControlJob.py#chsSayControlJob.py</file>
            <file>${scriptsDir}/chsHadoopUtils.py#chsHadoopUtils.py</file>
            <file>${scriptsDir}/simpleflake.py#simpleflake.py</file>
            <capture-output/>
        </shell>
        <ok to="validateControlPayload"/>
        <error to="stage-1-notify-job-failed"/>
    </action>

    <!-- We call control clean up here in order to clean the working file -->
    <decision name="validateControlPayload">
        <switch>
            <case to="stage-1-notify-status-started">
                ${
                    wf:actionData('retrieveControlJob')  ['returnCode'] ne 'FAILURE'
                }
            </case>
            <default to="stage-1-notify-control-failed"/>
        </switch>
    </decision>

    <!-- we have failed so tell the scorecard and exist  -->
    <!-- we have failed so tell the scorecard and exist  -->
    <action name="stage-1-notify-job-failed">
        <java>
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <main-class>net.chs.datalake.teradata.TeraStatusPush</main-class>
            <arg>-h</arg>
            <arg>${tdServer}</arg>
            <arg>-d</arg>
            <arg>${tdAuditDB}</arg>
            <arg>-u</arg>
            <arg>${tdUserID}</arg>
            <arg>-p</arg>
            <arg>${tdUserIDPassword}</arg>
            <arg>-j</arg>
            <!-- we probably do not even have a job id at this point -->
            <arg>unknown</arg>
            <arg>-f</arg>
            <arg>0000</arg>
            <arg>-s</arg>
            <arg>${sourceName}</arg>
            <arg>-z</arg>
            <arg>STAGE-1</arg>
            <arg>-x</arg>
            <arg>FAILED</arg>
            <arg>-m</arg>
            <arg>'${wf:id()} Stage-1 control job checks failed workflow exiting ...'</arg>
            <file>job.properties#job.properties</file>
            <capture-output/>
        </java>
        <ok to="stage-1-early-failure-cleanup"/>
        <error to="stage-1-early-failure-cleanup"/>
    </action>

    <action name="stage-1-notify-control-failed">
        <java>
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <main-class>net.chs.datalake.teradata.TeraStatusPush</main-class>
            <arg>-h</arg>
            <arg>${tdServer}</arg>
            <arg>-d</arg>
            <arg>${tdAuditDB}</arg>
            <arg>-u</arg>
            <arg>${tdUserID}</arg>
            <arg>-p</arg>
            <arg>${tdUserIDPassword}</arg>
            <arg>-j</arg>
            <!-- we probably do not even have a job id at this point -->
            <arg>unknown</arg>
            <arg>-f</arg>
            <arg>0000</arg>
            <arg>-s</arg>
            <arg>${sourceName}</arg>
            <arg>-z</arg>
            <arg>STAGE-1</arg>
            <arg>-x</arg>
            <arg>FAILED</arg>
            <arg>-m</arg>
            <arg>'${wf:id()} Stage-1 control file checks failed workflow exiting ...'</arg>
            <file>job.properties#job.properties</file>
            <capture-output/>
        </java>
        <ok to="stage-1-early-failure-cleanup"/>
        <error to="stage-1-early-failure-cleanup"/>
    </action>

    <!-- we have have everything we need to go, notity the SCoreCard we are now running -->
    <action name="stage-1-notify-status-started">
        <java>
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <main-class>net.chs.datalake.teradata.TeraStatusPush</main-class>
            <arg>-h</arg>
            <arg>${tdServer}</arg>
            <arg>-d</arg>
            <arg>${tdAuditDB}</arg>
            <arg>-u</arg>
            <arg>${tdUserID}</arg>
            <arg>-p</arg>
            <arg>${tdUserIDPassword}</arg>
            <arg>-j</arg>
            <arg>${wf:actionData('retrieveControlJob')['jobID']}</arg>
            <arg>-f</arg>
            <arg>0000</arg>
            <arg>-s</arg>
            <arg>${sourceName}</arg>
            <arg>-z</arg>
            <arg>STAGE-1</arg>
            <arg>-x</arg>
            <arg>STARTED</arg>
            <arg>-m</arg>
            <arg>'${wf:id()} Stage-1 workflow started now moving to part-1'</arg>
            <file>job.properties#job.properties</file>
            <capture-output/>
        </java>
<!--        <ok to="stage-1-part1"/>
        <error to="stage-1-part1"/>-->
        <ok to="process-stage-0-files"/>
        <error to="process-stage-0-files"/>

    </action>

    <action name='process-stage-0-files'>
        <shell xmlns="uri:oozie:shell-action:0.1">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <exec>/usr/bin/bash</exec>
            <argument>${sourcePath}</argument>
            <argument>${entity}</argument>
            <argument>${outputPath}</argument>
            <argument>${practiceMap}</argument>
            <argument>${entityMap}</argument>
            <argument>${tdServer}</argument>
            <argument>${tdUserID}</argument>
            <argument>${tdUserIDPassword}</argument>
            <argument>${tdTargetDB}</argument>
            <argument>divisional</argument>
            <argument>${stageOneDivisionMappingFile}</argument>
            <file>${scriptsDir}/AthenaStage1JarWrapper.sh#AthenaStage1JarWrapper.sh</file>
	    <capture-output/>
        </shell>
        <ok to="validate-process-stage-0-files-success"/>
        <error to="stage-1-notify-part-1-failed"/>
    </action>

    <!-- If the shell script above was a success it WILL NOT have returned a string like -->
    <!-- returnCode=FAILURE  so we test for it here before moving on, else cleanly exist -->
    <decision name="validate-process-stage-0-files-success">
        <switch>
            <case to="stage-1-notify-part-1-success">
                ${
                    wf:actionData('process-stage-0-files') ['returnCode'] ne 'FAILURE'
                }
            </case>
            <default to="stage-1-notify-part-1-failed"/>
        </switch>
    </decision>

    <action name="stage-1-notify-part-1-success">
        <java>
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <main-class>net.chs.datalake.teradata.TeraStatusPush</main-class>
            <arg>-h</arg>
            <arg>${tdServer}</arg>
            <arg>-d</arg>
            <arg>${tdAuditDB}</arg>
            <arg>-u</arg>
            <arg>${tdUserID}</arg>
            <arg>-p</arg>
            <arg>${tdUserIDPassword}</arg>
            <arg>-j</arg>
            <arg>${wf:actionData('retrieveControlJob')['jobID']}</arg>
            <arg>-f</arg>
            <arg>0000</arg>
            <arg>-s</arg>
            <arg>${sourceName}</arg>
            <arg>-z</arg>
            <arg>STAGE-1</arg>
            <arg>-x</arg>
            <arg>STAGE-1-COMPLETE</arg>
            <arg>-m</arg>
            <arg>'${wf:id()} part 1 success moving to athena stage-3'</arg>
            <file>job.properties#job.properties</file>
            <capture-output/>
        </java>
        <ok to="jump-to-stage-3-upload"/>
        <error to="jump-to-stage-3-upload"/>
    </action>

    <action name="stage-1-notify-part-1-failed">
        <java>
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <main-class>net.chs.datalake.teradata.TeraStatusPush</main-class>
            <arg>-h</arg>
            <arg>${tdServer}</arg>
            <arg>-d</arg>
            <arg>${tdAuditDB}</arg>
            <arg>-u</arg>
            <arg>${tdUserID}</arg>
            <arg>-p</arg>
            <arg>${tdUserIDPassword}</arg>
            <arg>-j</arg>
            <arg>${wf:actionData('retrieveControlJob')['jobID']}</arg>
            <arg>-f</arg>
            <arg>0000</arg>
            <arg>-s</arg>
            <arg>${sourceName}</arg>
            <arg>-z</arg>
            <arg>STAGE-1</arg>
            <arg>-x</arg>
            <arg>FAILING</arg>
            <arg>-m</arg>
            <arg>'${wf:id()} failed on part one with [ ${ wf:actionData('process-stage-0-files') ['returnCode']} ] exiting
                ...'
            </arg>
            <file>job.properties#job.properties</file>
            <capture-output/>
        </java>
        <ok to="stage-1-notify-early-failed"/>
        <error to="stage-1-notify-early-failed"/>
    </action>


    <!-- We call controll clean up here in order to clean the working file -->
    <action name="jump-to-stage-3-upload">
        <shell xmlns="uri:oozie:shell-action:0.1">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <exec>/usr/bin/bash</exec>
            <argument>athena_load.sh</argument>
            <argument>-i</argument>
            <argument>${workingFile}</argument>
            <file>${scriptsDir}/athena_load.sh#athena_load.shy</file>
            <capture-output/>
        </shell>
        <ok to="validateJump"/>
        <error to="notify-jump-failed"/>
    </action>

    <!-- If the shell script above was a success it WILL NOT have returned a string like -->
    <!-- returnCode=FAILURE  so we test for it here before moving on, else cleanly exist -->
    <decision name="validateJump">
        <switch>
            <case to="notify-jump-success">
                ${
                    wf:actionData('jump-to-stage-3-upload') ['returnCode'] ne 'FAILURE'
                }
            </case>
            <default to="notify-jump-failed"/>
        </switch>
    </decision>

    <!-- An example of moving data around on the hadoop to deep copy locations -->
    <action name="notify-jump-failed">
        <java>
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <main-class>net.chs.datalake.teradata.TeraStatusPush</main-class>
            <arg>-h</arg>
            <arg>${tdServer}</arg>
            <arg>-d</arg>
            <arg>${tdAuditDB}</arg>
            <arg>-u</arg>
            <arg>${tdUserID}</arg>
            <arg>-p</arg>
            <arg>${tdUserIDPassword}</arg>
            <arg>-j</arg>
            <arg>${wf:actionData('retrieveControlJob')['jobID']}</arg>
            <arg>-f</arg>
            <arg>0000</arg>
            <arg>-s</arg>
            <arg>${sourceName}</arg>
            <arg>-z</arg>
            <arg>STAGE-3</arg>
            <arg>-x</arg>
            <arg>FAILING</arg>
            <arg>-m</arg>
            <arg>'${wf:id()} failed on jump-to-stage-3-upload exiting ...'</arg>
            <file>job.properties#job.properties</file>
            <capture-output/>
        </java>
        <ok to="stage-1-notify-late-failed"/>
        <error to="stage-1-notify-late-failed"/>
    </action>

    <!-- An example of moving data around on the hadoop to deep copy locations -->
    <action name="notify-jump-success">
        <java>
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <main-class>net.chs.datalake.teradata.TeraStatusPush</main-class>
            <arg>-h</arg>
            <arg>${tdServer}</arg>
            <arg>-d</arg>
            <arg>${tdAuditDB}</arg>
            <arg>-u</arg>
            <arg>${tdUserID}</arg>
            <arg>-p</arg>
            <arg>${tdUserIDPassword}</arg>
            <arg>-j</arg>
            <arg>${wf:actionData('retrieveControlJob')['jobID']}</arg>
            <arg>-f</arg>
            <arg>0000</arg>
            <arg>-s</arg>
            <arg>${sourceName}</arg>
            <arg>-z</arg>
            <arg>STAGE-3</arg>
            <arg>-x</arg>
            <arg>WORKING</arg>
            <arg>-m</arg>
            <arg>'${wf:id()} success on jump-to-stage-3-moving to  INQUEUE STAGE-3 completed ...'</arg>
            <file>job.properties#job.properties</file>
            <capture-output/>
        </java>
        <ok to="notify-work-queue"/>
        <error to="notify-work-queue"/>
    </action>

	<action name="stage-2-write-que-record">
		<java>
			<job-tracker>${jobTracker}</job-tracker>
			<name-node>${nameNode}</name-node>
			<main-class>net.chs.datalake.teradata.TeraWorkQue</main-class>
			<arg>-h</arg>
			<arg>${tdServer}</arg>
			<arg>-d</arg>
			<arg>${tdAuditDB}</arg>
			<arg>-u</arg>
			<arg>${tdUserID}</arg>
			<arg>-p</arg>
			<arg>${tdUserIDPassword}</arg>
			<arg>-j</arg>
			<arg>${wf:actionData('retrieveControlJob')['jobID']}</arg>
			<arg>-f</arg>
			<arg>${divisionID}</arg>
			<arg>-s</arg>
			<arg>${sourceName}</arg>
			<arg>-z</arg>
			<arg>noop</arg>
			<arg>-x</arg>
			<arg>STAGE_3_COMPLETE</arg>
		<file>job.properties#job.properties</file>
		<capture-output/>
		</java>
		<ok to="success-cleanup"/>
		<error to="success-cleanup"/>
	</action>


    <!-- We have succesfully completed, remove our WORKING.TXT file -->
    <action name="stage-1-finished">
        <fs>
            <delete path="${workingFile}"/>
            <!--Do any other clean up here -->
            <!--<delete  path="${errorDataDir}"/>
            <mkdir   path="${errorDataDir}"/>
            <chmod   path='${errorDataDir}' permissions='755' dir-files='false'/>-->
        </fs>
        <ok to="stage-1-notify-completed"/>
        <error to="stage-1-notify-completed"/>
    </action>

    <action name="stage-1-notify-completed">
        <java>
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <main-class>net.chs.datalake.teradata.TeraStatusPush</main-class>
            <arg>-h</arg>
            <arg>${tdServer}</arg>
            <arg>-d</arg>
            <arg>${tdAuditDB}</arg>
            <arg>-u</arg>
            <arg>${tdUserID}</arg>
            <arg>-p</arg>
            <arg>${tdUserIDPassword}</arg>
            <arg>-j</arg>
            <arg>${wf:actionData('retrieveControlJob')['jobID']}</arg>
            <arg>-f</arg>
            <arg>0000</arg>
            <arg>-s</arg>
            <arg>${sourceName}</arg>
            <arg>-z</arg>
            <arg>STAGE-3</arg>
            <arg>-x</arg>
            <arg>COMPLETED</arg>
            <arg>-m</arg>
            <arg>'${wf:id()} Done with stage-3'</arg>
            <file>job.properties#job.properties</file>
            <capture-output/>
        </java>
        <ok to="end"/>
        <error to="end"/>
    </action>

    <!--Send status via email      -->
    <action name="email-failure">
        <email xmlns="uri:oozie:email-action:0.1">
            <to>${toEmailAddress}</to>
            <subject>Status of workflow ${wf:id()}</subject>
            <body>The workflow ${wf:name()} with id -${wf:id()}, had issues and
                will be kill; The error logged is:
                ${wf:errorMessage(wf:lastErrorNode()); }
            </body>
        </email>
        <ok to="stage-1-notify-early-failed"/>
        <error to="stage-1-notify-early-failed"/>
    </action>

    <action name="email-success">
        <email xmlns="uri:oozie:email-action:0.1">
            <to>${toEmailAddress}</to>
            <subject>Status of workflow ${wf:id()}</subject>
            <body>The workflow ${wf:name()} with id -${wf:id()}, completed successfully.
            </body>
        </email>
        <ok to="end"/>
        <error to="end"/>
    </action>

    <action name="stage-1-notify-early-failed">
        <java>
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <main-class>net.chs.datalake.teradata.TeraStatusPush</main-class>
            <arg>-h</arg>
            <arg>${tdServer}</arg>
            <arg>-d</arg>
            <arg>${tdAuditDB}</arg>
            <arg>-u</arg>
            <arg>${tdUserID}</arg>
            <arg>-p</arg>
            <arg>${tdUserIDPassword}</arg>
            <arg>-j</arg>
            <arg>${wf:actionData('retrieveControlJob')['jobID']}</arg>
            <arg>-f</arg>
            <arg>${divisionID}</arg>
            <arg>-s</arg>
            <arg>${sourceName}</arg>
            <arg>-z</arg>
            <arg>STAGE-1</arg>
            <arg>-x</arg>
            <arg>FAILED</arg>
            <arg>-m</arg>
            <arg>'${wf:id()} workflow exiting ....'</arg>
            <file>job.properties#job.properties</file>
            <capture-output/>
        </java>
        <ok to="stage-1-early-failure-cleanup"/>
        <error to="stage-1-early-failure-cleanup"/>
    </action>

    <action name="stage-1-notify-late-failed">
        <java>
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <main-class>net.chs.datalake.teradata.TeraStatusPush</main-class>
            <arg>-h</arg>
            <arg>${tdServer}</arg>
            <arg>-d</arg>
            <arg>${tdAuditDB}</arg>
            <arg>-u</arg>
            <arg>${tdUserID}</arg>
            <arg>-p</arg>
            <arg>${tdUserIDPassword}</arg>
            <arg>-j</arg>
            <arg>${wf:actionData('retrieveControlJob')['jobID']}</arg>
            <arg>-f</arg>
            <arg>${divisionID}</arg>
            <arg>-s</arg>
            <arg>${sourceName}</arg>
            <arg>-z</arg>
            <arg>STAGE-1</arg>
            <arg>-x</arg>
            <arg>FAILED</arg>
            <arg>-m</arg>
            <arg>'${wf:id()} workflow exiting ....'</arg>
            <file>job.properties#job.properties</file>
            <capture-output/>
        </java>
        <ok to="stage-1-late-failure-cleanup"/>
        <error to="stage-1-late-failure-cleanup"/>
    </action>

    <!-- We have somehow failed early in the process, remove our WORKING.TXT file -->
    <action name="stage-1-early-failure-cleanup">
        <fs>
            <delete path="${workingFile}"/>
            <!--Do any other clean up here -->
            <!--<delete  path="${errorDataDir}"/>
            <mkdir   path="${errorDataDir}"/>
            <chmod   path='${errorDataDir}' permissions='755' dir-files='false'/>-->
        </fs>
        <ok to="kill"/>
        <error to="kill"/>
    </action>

    <!-- We have somehow failed late in the process more clean up to do, remove our WORKING.TXT file -->
    <action name="stage-1-late-failure-cleanup">
        <fs>
            <delete path="${workingFile}"/>
            <!--Do any other clean up here -->
            <!--<delete  path="${errorDataDir}"/>
            <mkdir   path="${errorDataDir}"/>
            <chmod   path='${errorDataDir}' permissions='755' dir-files='false'/>-->
        </fs>
        <ok to="kill"/>
        <error to="kill"/>
    </action>

    <!-- End the workflows as having failed -->
    <kill name="kill">
        <message>"Killed job due to error:
            ${wf:errorMessage(wf:lastErrorNode())}"
        </message>
    </kill>

    <end name="end"/>

</workflow-app> 
